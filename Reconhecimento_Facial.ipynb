{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/NEu8VbJmr5niPuvrxzB4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicaneli/Deteccao-em-imagens-rede-Yolo/blob/main/Reconhecimento_Facial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detecção e Reconhecimento Facial\n",
        "\n",
        "O presente projeto tem como objetivo desenvolver um sistema automatizado de detecção e reconhecimento de faces, aplicando-o especificamente para identificar os personagens principais da série *The Big Bang Theory*. A solução combina técnicas modernas de visão computacional e aprendizado profundo para realizar duas tarefas principais: detecção de faces em imagens ou vídeos e reconhecimento de identidades específicas.\n",
        "\n",
        "### 1. Metodologia\n",
        "\n",
        "**Detecção de faces:**\n",
        "Para localizar rostos nas imagens, foi utilizada a rede MTCNN (Multi-task Cascaded Convolutional Networks).\n",
        "\n",
        "**Reconhecimento facial:** FaceNet e um classificador leve (KNN ou SVM).\n",
        "\n",
        "### 2. Base de Dados\n",
        "\n",
        "Para o reconhecimento dos personagens, foi construída uma base de 12 imagens por personagem, contendo apenas o rosto, garantindo um treinamento eficiente mesmo com um número reduzido de exemplos. Técnicas de *data augmentation* (giro, flip, ajustes de brilho) foram aplicadas para aumentar virtualmente o conjunto de dados e melhorar a robustez do modelo.\n",
        "\n",
        "\n",
        "### 3. Tecnologias e Ferramentas\n",
        "\n",
        "* **Python** com bibliotecas: OpenCV, MTCNN, keras-facenet, scikit-learn.\n",
        "* **Redes neurais profundas**: MTCNN para detecção e FaceNet para reconhecimento.\n",
        "* **Classificador leve**: KNN, para mapear embeddings em identidades de personagens.\n",
        "* **Data augmentation**: aumento de base para robustez.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NbocCHjGDyqK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9wauRk9lDsY6"
      },
      "outputs": [],
      "source": [
        "# Imports e parâmetros\n",
        "import os\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import random\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O the-big-bang-theory-3.jpg 'https://observatoriodocinema.com.br/wp-content/plugins/seox-image-magick/imagick_convert.php?width=1869&height=1402&format=.jpg&quality=91&imagick=/wp-content/uploads/2022/03/the-big-bang-theory-3.jpg'\n",
        "!wget -O Amy_TBBT.jpg  'https://aventurasnahistoria.com.br/wp-content/uploads/curiosidades/amy_fowler_mayim_bialik.jpg'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHRWekI0CXE8",
        "outputId": "c32ec22e-64bf-4445-8bbf-8fc9a29d1b06"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-15 21:33:13--  https://observatoriodocinema.com.br/wp-content/plugins/seox-image-magick/imagick_convert.php?width=1869&height=1402&format=.jpg&quality=91&imagick=/wp-content/uploads/2022/03/the-big-bang-theory-3.jpg\n",
            "Resolving observatoriodocinema.com.br (observatoriodocinema.com.br)... 104.21.70.51, 172.67.220.1, 2606:4700:3037::6815:4633, ...\n",
            "Connecting to observatoriodocinema.com.br (observatoriodocinema.com.br)|104.21.70.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [image/jpg]\n",
            "Saving to: ‘the-big-bang-theory-3.jpg’\n",
            "\n",
            "the-big-bang-theory     [   <=>              ] 559.53K   844KB/s    in 0.7s    \n",
            "\n",
            "2025-09-15 21:33:15 (844 KB/s) - ‘the-big-bang-theory-3.jpg’ saved [572955]\n",
            "\n",
            "--2025-09-15 21:33:15--  https://aventurasnahistoria.com.br/wp-content/uploads/curiosidades/amy_fowler_mayim_bialik.jpg\n",
            "Resolving aventurasnahistoria.com.br (aventurasnahistoria.com.br)... 172.67.213.242, 104.21.16.157, 2606:4700:3036::6815:109d, ...\n",
            "Connecting to aventurasnahistoria.com.br (aventurasnahistoria.com.br)|172.67.213.242|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131814 (129K) [image/jpeg]\n",
            "Saving to: ‘Amy_TBBT.jpg’\n",
            "\n",
            "Amy_TBBT.jpg        100%[===================>] 128.72K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-09-15 21:33:15 (3.97 MB/s) - ‘Amy_TBBT.jpg’ saved [131814/131814]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Banco de faces para reconhecimento\n",
        "dataset_path = \"/content/TBBT_Faces\"\n",
        "\n",
        "# Dataset Big Bang Theory\n",
        "!wget -O TBBT.zip \"https://github.com/monicaneli/Reconhecimento-Facial/raw/main/TBBT_Faces.zip\"\n",
        "!unzip -q TBBT.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A27lc6cXExtn",
        "outputId": "71468fbf-33c2-4248-abe4-765c94516318"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-15 21:33:15--  https://github.com/monicaneli/Reconhecimento-Facial/raw/main/TBBT_Faces.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/monicaneli/Reconhecimento-Facial/main/TBBT_Faces.zip [following]\n",
            "--2025-09-15 21:33:15--  https://raw.githubusercontent.com/monicaneli/Reconhecimento-Facial/main/TBBT_Faces.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1004611 (981K) [application/zip]\n",
            "Saving to: ‘TBBT.zip’\n",
            "\n",
            "TBBT.zip            100%[===================>] 981.07K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-09-15 21:33:16 (16.9 MB/s) - ‘TBBT.zip’ saved [1004611/1004611]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn\n",
        "!pip install keras-facenet\n",
        "!pip install lz4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KM8uElwE0uM",
        "outputId": "129d8b38-e817-4547-9044-8036d3459e21"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (1.5.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.12/dist-packages (from mtcnn) (4.4.4)\n",
            "Requirement already satisfied: keras-facenet in /usr/local/lib/python3.12/dist-packages (0.3.2)\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.12/dist-packages (from keras-facenet) (1.0.0)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from mtcnn->keras-facenet) (1.5.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.12/dist-packages (from mtcnn->keras-facenet) (4.4.4)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.12/dist-packages (4.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from mtcnn import MTCNN\n",
        "from keras_facenet import FaceNet"
      ],
      "metadata": {
        "id": "IeifRhpnHGBR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecção de faces com MTCNN\n",
        "\n",
        "Para localizar rostos nas imagens, foi utilizada a rede MTCNN (Multi-task Cascaded Convolutional Networks).\n",
        "\n",
        "Esta rede é projetada para detectar rostos com alta precisão em diferentes posições, ângulos e condições de iluminação. Ela realiza a detecção em três estágios cascata, refinando progressivamente as localizações de face e estimando pontos-chave faciais (olhos, nariz, boca), permitindo um recorte preciso dos rostos.\n"
      ],
      "metadata": {
        "id": "ztvbkz_IbLsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rede MTCNN (Multi-task Cascaded Convolutional Networks)\n",
        "detector = MTCNN()"
      ],
      "metadata": {
        "id": "XASDuBPOBykC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "a816db6b-5970-4384-bb64-697d88dabaff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "LZ4 is not installed. Install it with pip: https://python-lz4.readthedocs.io/",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1455214306.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Rede MTCNN (Multi-task Cascaded Convolutional Networks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mtcnn/mtcnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stages, device)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Instantiate stages if necessary (can pass already instantiated stages too)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstages\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mtcnn/stages/stage_pnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stage_name, stage_id, weights)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Building the model (no need to specify input shape if default is provided)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load pre-trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mtcnn/utils/tensorflow.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(weights_name)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# First checks the local filesystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# If no file is found, raise an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             with _validate_fileobject_and_memmap(f, filename, mmap_mode) as (\n\u001b[0m\u001b[1;32m    737\u001b[0m                 \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                 \u001b[0mvalidated_mmap_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle_utils.py\u001b[0m in \u001b[0;36m_validate_fileobject_and_memmap\u001b[0;34m(fileobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;31m# correct decompressor file object, wrapped in a buffer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mcompressor_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_COMPRESSORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompressor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0minst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompressor_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompressor_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_buffered_read_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/compressor.py\u001b[0m in \u001b[0;36mdecompressor_file\u001b[0;34m(self, fileobj)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecompressor_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;34m\"\"\"Returns an instance of a decompressor file object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/compressor.py\u001b[0m in \u001b[0;36m_check_versions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlz4\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLZ4_NOT_INSTALLED_ERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mlz4_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlz4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlz4_version\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"v\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: LZ4 is not installed. Install it with pip: https://python-lz4.readthedocs.io/"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste de detecção de faces\n",
        "img = cv2.imread(\"/content/Amy_TBBT.jpg\")\n",
        "rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "faces = detector.detect_faces(rgb)\n",
        "\n",
        "for f in faces:\n",
        "    x, y, w, h = f['box']\n",
        "    x, y = max(0,x), max(0,y)  # Garantir que não seja negativo\n",
        "    face_crop = rgb[y:y+h, x:x+w]\n",
        "\n",
        "    # Salvar face recortada\n",
        "    cv2.imwrite(\"face_detected.jpg\", cv2.cvtColor(face_crop, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    # Criar uma cópia para desenhar o retângulo\n",
        "    img_overlay = img.copy()\n",
        "\n",
        "    # Desenhar retângulo verde ao redor da face\n",
        "    cv2.rectangle(img_overlay, (x, y), (x+w, y+h), color=(0,255,0), thickness=3)\n",
        "\n",
        "    # Mostrar imagem com retângulo\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(cv2.cvtColor(img_overlay, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "dGwvQYRfCMCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconhcimento Facial\n",
        "\n",
        "Após a detecção, cada face é processada pela rede FaceNet, que gera embeddings (vetores de características) para cada rosto.\n",
        "\n",
        "O FaceNet é uma rede profunda pré-treinada que mapeia faces em um espaço de alta dimensão, de forma que rostos da mesma pessoa fiquem próximos entre si, enquanto rostos de pessoas diferentes fiquem distantes.\n",
        "\n",
        "Esses embeddings são então utilizados para treinar um classificador leve (KNN ou SVM), capaz de reconhecer cada personagem a partir de um pequeno conjunto de imagens de referência."
      ],
      "metadata": {
        "id": "_FXzdJvDBVlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar FaceNet\n",
        "embedder = FaceNet()\n",
        "\n",
        "# Função para extrair embeddings de uma face\n",
        "def get_embedding(face_img):\n",
        "    # Redimensionar para 160x160, que é o padrão do FaceNet\n",
        "    face = cv2.resize(face_img, (160, 160))\n",
        "    face = face.astype(\"float32\")\n",
        "    face = np.expand_dims(face, axis=0)\n",
        "    return embedder.embeddings(face)[0]\n"
      ],
      "metadata": {
        "id": "AJPY3WGmbNiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comparar face detectada com banco\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def recognize_face(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        return \"Erro: imagem não carregada\"\n",
        "    emb = get_embedding(img)\n",
        "    pred = knn.predict([emb])[0]\n",
        "    proba = knn.predict_proba([emb])[0]\n",
        "    return le.inverse_transform([pred])[0], np.max(proba)\n",
        "\n",
        "def recognize_face2(face_img, threshold=0.8):\n",
        "    emb = get_embedding(face_img)\n",
        "    best_match = None\n",
        "    best_score = float(\"inf\")\n",
        "\n",
        "    for person, embeddings in known_faces.items():\n",
        "        for ref_emb in embeddings:\n",
        "            score = norm(emb - ref_emb)\n",
        "            if score < best_score:\n",
        "                best_score = score\n",
        "                best_match = person\n",
        "\n",
        "    if best_score < threshold:\n",
        "        return best_match, best_score\n",
        "    else:\n",
        "        return \"Desconhecido\", best_score\n"
      ],
      "metadata": {
        "id": "BhJnjnYObqbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pasta de rostos extraídos do dataset\n",
        "embedder = FaceNet()\n",
        "X, y = [], []\n",
        "\n",
        "def augment_image(img):\n",
        "    \"\"\"Aplica aumentos simples em uma imagem\"\"\"\n",
        "    aug_imgs = []\n",
        "\n",
        "    # 1. Flip horizontal\n",
        "    aug_imgs.append(cv2.flip(img, 1))\n",
        "\n",
        "    # 2. Rotação pequena\n",
        "    angle = random.choice([-10, -5, 5, 10])\n",
        "    h, w = img.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
        "    aug_imgs.append(cv2.warpAffine(img, M, (w, h)))\n",
        "\n",
        "    # 3. Alterar brilho\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    hsv = np.array(hsv, dtype=np.float64)\n",
        "    hsv[...,1] = hsv[...,1]*random.uniform(0.8,1.2)\n",
        "    hsv[...,2] = hsv[...,2]*random.uniform(0.7,1.3)\n",
        "    hsv[hsv > 255] = 255\n",
        "    aug_imgs.append(cv2.cvtColor(np.array(hsv, dtype=np.uint8), cv2.COLOR_HSV2BGR))\n",
        "\n",
        "    return aug_imgs\n",
        "\n",
        "# Preparando o dataset\n",
        "for person in os.listdir(dataset_path):\n",
        "    person_path = os.path.join(dataset_path, person)\n",
        "    if not os.path.isdir(person_path):\n",
        "        continue\n",
        "\n",
        "    for img_name in os.listdir(person_path):\n",
        "        img_path = os.path.join(person_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, (160, 160))\n",
        "\n",
        "        # Embedding da imagem original\n",
        "        X.append(embedder.embeddings([img])[0])\n",
        "        y.append(person)\n",
        "\n",
        "        # Augmentation → Embeddings das variações\n",
        "        for aug in augment_image(img):\n",
        "            aug = cv2.resize(aug, (160, 160))\n",
        "            X.append(embedder.embeddings([aug])[0])\n",
        "            y.append(person)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Total de embeddings após augmentation:\", X.shape, \"Labels:\", len(y))"
      ],
      "metadata": {
        "id": "fuDTj8wKxbUp",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformar rótulos em inteiros\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "\n",
        "# Treinar um KNN simples\n",
        "knn = KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\")\n",
        "knn.fit(X, y_enc)\n",
        "\n",
        "print(\"Classes:\", le.classes_)\n"
      ],
      "metadata": {
        "id": "_wPgUQoMxroi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria o classificador SVM com kernel linear\n",
        "svm = SVC(kernel='linear', probability=True)  # probability=True permite prever confiança\n",
        "svm.fit(X, y_enc)\n",
        "\n",
        "print(\"Classes aprendidas pelo SVM:\", le.classes_)"
      ],
      "metadata": {
        "id": "AwsEvT2SH8Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_face_svm(image_path):\n",
        "    img = cv2.imread(image_path)  # Read the image from the path\n",
        "    if img is None:\n",
        "        return \"Erro: imagem não carregada\", 0.0 # Return error if image not loaded\n",
        "    face_resized = cv2.resize(img, (160, 160))\n",
        "    emb = embedder.embeddings([face_resized])[0]\n",
        "    pred = svm.predict([emb])[0]\n",
        "    proba = np.max(svm.predict_proba([emb])[0])\n",
        "    label = le.inverse_transform([pred])[0]\n",
        "    return label, proba\n",
        "\n",
        "# Teste\n",
        "test_img = '/content/Amy_TBBT.jpg'\n",
        "label, score = recognize_face_svm(test_img)\n",
        "print(\"Reconhecido como:\", label, \"com confiança:\", score)"
      ],
      "metadata": {
        "id": "H86j1mw7IE0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo: testar com uma imagem da Amy\n",
        "test_img = '/content/Amy_TBBT.jpg'\n",
        "label, score = recognize_face(test_img)\n",
        "print(\"Reconhecido como:\", label, \" (confiança:\", score, \")\")"
      ],
      "metadata": {
        "id": "X4pwtQPuxvZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reconhecimeno de múltiplas faces em uma imagem\n"
      ],
      "metadata": {
        "id": "8l-qVMdhHg_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_faces_in_frame(frame_path, knn, embedder, le):\n",
        "    # Carregar frame\n",
        "    img = cv2.imread(frame_path)\n",
        "    if img is None:\n",
        "        return \"Erro ao carregar imagem\"\n",
        "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Detectar faces\n",
        "    results = detector.detect_faces(rgb)\n",
        "    print(\"Faces detectadas:\", len(results))\n",
        "\n",
        "    for res in results:\n",
        "        x, y, w, h = res['box']\n",
        "        face = rgb[y:y+h, x:x+w]\n",
        "        face = cv2.resize(face, (160, 160))\n",
        "\n",
        "        # Extrair embedding\n",
        "        emb = embedder.embeddings([face])[0]\n",
        "\n",
        "        # Predição\n",
        "        pred = knn.predict([emb])[0]\n",
        "        proba = knn.predict_proba([emb])[0]\n",
        "        label = le.inverse_transform([pred])[0]\n",
        "        score = np.max(proba)\n",
        "\n",
        "        # Desenhar bounding box e nome\n",
        "        cv2.rectangle(rgb, (x, y), (x+w, y+h), (0,255,0), 2)\n",
        "        cv2.putText(rgb, f\"{label} ({score:.2f})\", (x, y-10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)\n",
        "\n",
        "    # Mostrar imagem final\n",
        "    plt.figure(figsize=(10,8))\n",
        "    plt.imshow(rgb)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "xUexkYLB779g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_path = \"/content/the-big-bang-theory-3.jpg\"  # vários personagens\n",
        "recognize_faces_in_frame(frame_path, knn, embedder, le)"
      ],
      "metadata": {
        "id": "8RwCyfra2M0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusão\n",
        "\n",
        "O sistema proposto combina detecção de faces de alta precisão com reconhecimento baseado em embeddings, permitindo identificar os personagens de *The Big Bang Theory* de forma automática e eficiente.\n",
        "\n",
        "A escolha de MTCNN e FaceNet garante robustez frente a variações de pose, expressão e iluminação, oferecendo uma solução prática para aplicações de reconhecimento facial em séries, vídeos ou imagens estáticas.\n",
        "\n",
        "\n",
        "## Referências\n",
        "\n",
        "[1] YOLOv4 Object Detection on Webcam In Google Colab por [Jack Wotherspoon](https://github.com/jackwotherspoon)\n",
        "\n",
        "[2] Bootcamp BairesDev - Machine Learning Training pela DIO"
      ],
      "metadata": {
        "id": "OeTKXgd6OVel"
      }
    }
  ]
}